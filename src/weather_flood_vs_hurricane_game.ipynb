{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.4.7)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langsmith in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.42)\n",
      "Collecting langsmith\n",
      "  Downloading langsmith-0.3.43-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: langgraph-supervisor in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.0.25)\n",
      "Collecting langgraph-supervisor\n",
      "  Downloading langgraph_supervisor-0.0.27-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (0.3.61)\n",
      "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (2.0.26)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (0.2.1)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (0.1.63)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (2.11.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.2.5)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_openai) (1.78.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (3.10.16)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (24.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (0.23.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.9.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.20)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\m_saj\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Downloading langsmith-0.3.43-py3-none-any.whl (361 kB)\n",
      "Downloading langgraph_supervisor-0.0.27-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: langsmith, langgraph-supervisor\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.3.42\n",
      "    Uninstalling langsmith-0.3.42:\n",
      "      Successfully uninstalled langsmith-0.3.42\n",
      "  Attempting uninstall: langgraph-supervisor\n",
      "    Found existing installation: langgraph-supervisor 0.0.25\n",
      "    Uninstalling langgraph-supervisor-0.0.25:\n",
      "      Successfully uninstalled langgraph-supervisor-0.0.25\n",
      "Successfully installed langgraph-supervisor-0.0.27 langsmith-0.3.43\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Install required packages\n",
    "%pip install -U langgraph langchain_community langchain_openai langsmith langgraph-supervisor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variable Initialization\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_if_undefined(var_name: str):\n",
    "    \"\"\"\n",
    "    Set an environment variable if it is not already defined.\n",
    "    \n",
    "    Args:\n",
    "        var_name (str): Name of the environment variable to set.\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var_name):\n",
    "        # Securely prompt the user for input without echoing it on screen\n",
    "        os.environ[var_name] = getpass.getpass(f\"Please provide your {var_name}: \")\n",
    "\n",
    "# ---- Environment Variables Required ----\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")         # API key for OpenAI models\n",
    "_set_if_undefined(\"ANTHROPIC_API_KEY\")      # API key for OpenAI models\n",
    "_set_if_undefined(\"LANGSMITH_TRACING\")      # Enable LangSmith tracing (\"true\" to enable)\n",
    "_set_if_undefined(\"LANGSMITH_API_KEY\")      # API key for LangSmith platform\n",
    "_set_if_undefined(\"OPENAI_MODEL\")           # Model name (e.g., \"gpt-4.1\" \"gpt-4o\", \"gpt-3.5-turbo\")\n",
    "_set_if_undefined(\"ANTHROPIC_MODEL\")        # Model name (e.g., \"claude-sonnet-4-20250514, claude-3-7-sonnet-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prisoner's Dilemma\n",
    "# - Two agents (Agent1 and Agent2) choose simultaneously between \"Cooperate\" or \"Defect\".\n",
    "# - Each agent evaluates payoffs based on the provided payoff matrix.\n",
    "# - Each agent finds its dominant strategy (the best action regardless of the other's choice).\n",
    "# - Nash Equilibrium occurs when no agent can improve their outcome by changing strategy unilaterally (both defect).\n",
    "\n",
    "# ---- Imports ----\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import json\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Literal, Annotated\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import StateGraph,MessagesState, START, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel\n",
    "from pprint import pprint\n",
    "from langchain.globals import set_debug\n",
    "\n",
    "\n",
    "set_debug(False)\n",
    "# ---- LLM Setup ----\n",
    "\n",
    "# Load the default model from environment variables\n",
    "openai_model = os.environ[\"OPENAI_MODEL\"]\n",
    "# Initialize the LLM (Large Language Model) interface\n",
    "openai_llm = ChatOpenAI(model=openai_model)\n",
    "\n",
    "# Load the default model from environment variables\n",
    "anthropic_model = os.environ[\"ANTHROPIC_MODEL\"]\n",
    "# Initialize the LLM (Large Language Model) interface\n",
    "anthropic_llm = ChatAnthropic(model=anthropic_model)\n",
    "\n",
    "class OverallState(MessagesState):\n",
    "    \"\"\"State to track bidder1, bidder2, bidder3 work.\"\"\"\n",
    "    \n",
    "    selected_bidder_for_flood_report: str\n",
    "    selected_bidder_for_hurricane_report : str\n",
    "    final_report: str\n",
    "    step: int\n",
    "    weather_data : str\n",
    "\n",
    "\n",
    "# Define a dummy luggage_support_tool\n",
    "@tool\n",
    "def get_player_card_tool(agent_name: Annotated[str, \"name of the agent or player who is requesting their playercard.\"]):\n",
    "    \"\"\"Tool to fetch player card information for a given agent or player name.\"\"\"\n",
    "    \n",
    "    player_cards = {\n",
    "        \"bidder1\": {\"flood_knowledge\": random.randint(5, 8), \"hurricane_knowledge\": random.randint(3, 8), \"response_time\": random.randint(0, 3)},\n",
    "        \"bidder2\": {\"flood_knowledge\": random.randint(3, 7), \"hurricane_knowledge\": random.randint(2, 9), \"response_time\": random.randint(0, 3)}\n",
    "    }\n",
    "    return player_cards.get(agent_name, {\"error\": \"unknown player\"})\n",
    "\n",
    "class selected_bidders(BaseModel):\n",
    "    \"\"\"class to store the selected agents or players for flood and hurrican report generation.\"\"\"\n",
    "    selected_bidder_for_flood_report:  Annotated[str, \"selected player or bidder to generate report on flood based on the provided weather data\"]\n",
    "    selected_bidder_for_hurricane_report:  Annotated[str, \"selected player or bidder to generate report on hurricane based on the provided weather data\"]\n",
    "\n",
    "\n",
    "class player_card(BaseModel):\n",
    "    \"\"\"class to store player or agents data.\"\"\"\n",
    "    player_name: Annotated[str, \"name of the player or agent\"]\n",
    "    flood_knowledge_out_of_10 : Annotated[int, \"flood knowledge out of 10\"]\n",
    "    hurricane_knowledge_out_of_10 : Annotated[int, \"hurricane knowledge out of 10\"]\n",
    "    response_time_in_seconds: Annotated[int, \"response time in seconds\"] \n",
    "\n",
    "# Creating a generalized agent creation function to reduce redundancy\n",
    "def create_bidder_agent_for_player_card(agent_name: str):\n",
    "    \"\"\"Creates a React agent for the bidder.\"\"\"\n",
    "    return create_react_agent(\n",
    "        openai_llm,  \n",
    "        tools=[get_player_card_tool],  \n",
    "        prompt=f\"You are a helpful agent, your name is {agent_name}. Your task is to get the player card data for yourself. You can use tools to get the data.\",\n",
    "        response_format=player_card\n",
    "    )\n",
    "\n",
    "get_bidder1_playercard = create_bidder_agent_for_player_card(\"bidder1\")\n",
    "get_bidder2_playercard = create_bidder_agent_for_player_card(\"bidder2\")\n",
    "\n",
    "def create_prompt(input: MessagesState):\n",
    "    return (\" Based on the following data which bidder would you choose to generate flood and hurricane reports? \"\n",
    "            \" make sure you consider their knowledge in each subject and response time. \"\n",
    "            \" Response time is not important when a bidder has better knowledge about the subject. \"\n",
    "            \" If bidders have similar strengths then choose one with the shorter response time. \"\n",
    "            f\" Here is the Data : {input}\")\n",
    "\n",
    "get_selected_bidders = create_react_agent(\n",
    "    openai_llm,  \n",
    "    tools=[],  \n",
    "    prompt=create_prompt, \n",
    "    response_format=selected_bidders\n",
    ")\n",
    "\n",
    "\n",
    "final_report_generator = create_react_agent(\n",
    "    openai_llm,  \n",
    "    tools=[],  \n",
    "    prompt=\"based on the message history, generate a final consolidated report on flood and hurricane.\"\n",
    ")\n",
    "\n",
    "\n",
    "# Function to handle bidding process and generating responses\n",
    "def handle_bidder_steps(agent_name: str, state: OverallState, step: str):\n",
    "    \"\"\"Handles the bidder's steps and actions based on the state.\"\"\"\n",
    "    \n",
    "    print(agent_name)\n",
    "    if(step == \"step-1\"):\n",
    "        print(\"XXXXXXXX  step-1\")\n",
    "        response = get_bidder1_playercard.invoke(state)\n",
    "        player_card_data = response[\"structured_response\"]\n",
    "    \n",
    "        \n",
    "        return Command(\n",
    "            goto=[\"auctioneer\"],\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=f\"{agent_name} response time: {player_card_data['response_time']}\", name=agent_name),\n",
    "                    HumanMessage(content=f\"{agent_name} flood knowledge: {player_card_data['flood_knowledge']}\", name=agent_name),\n",
    "                    HumanMessage(content=f\"{agent_name} hurricane knowledge: {player_card_data['hurricane_knowledge']}\", name=agent_name),\n",
    "                    HumanMessage(content=\"Shared the player card data\", name=agent_name)\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    elif step == \"step-2\":\n",
    "        print(\"XXXXXXXX  step-2\")\n",
    "        for_flood = state[\"selected_bidder_for_flood_report\"]\n",
    "        for_hurricane = state[\"selected_bidder_for_hurricane_report\"]\n",
    "        \n",
    "        print(for_flood)\n",
    "        print(for_hurricane)\n",
    "\n",
    "        if(for_flood == agent_name or for_hurricane == agent_name): \n",
    "                       \n",
    "            messages = [f\"Based on the following data, generate a report on the given topic(s). Only write about the topics mentioned below. Here is the data: {state['weather_data']} \"]\n",
    "            \n",
    "            if for_flood == agent_name:\n",
    "                messages.append(\"Topic: flood\")\n",
    "            if for_hurricane == agent_name:\n",
    "                messages.append(\"Topic: hurricane\")\n",
    "\n",
    "            report = openai_llm.invoke(messages)\n",
    "\n",
    "            return Command(\n",
    "                goto=[\"auctioneer\"],\n",
    "                update={\n",
    "                    \"messages\": [\n",
    "                        HumanMessage(content=f\"generated report(s) : {report.content} \", name=agent_name)\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "        else: \n",
    "            return Command(\n",
    "                goto=[\"auctioneer\"]\n",
    "            )\n",
    "    \n",
    "    else:\n",
    "        return Command(\n",
    "            goto=[\"auctioneer\"],\n",
    "            update={\"messages\": [HumanMessage(content=\"Unknown step\", name=agent_name)]}\n",
    "        )\n",
    "    \n",
    "def bidder1(state: OverallState) -> Command[Literal[\"auctioneer\"]]:\n",
    "    \"\"\"\n",
    "    You are bidder1. \n",
    "    \"\"\"\n",
    "    step = state[\"messages\"][-1].content\n",
    "    return handle_bidder_steps(\"bidder1\", state, step)\n",
    "\n",
    "def bidder2(state: OverallState) -> Command[Literal[\"auctioneer\"]]:\n",
    "    \"\"\"\n",
    "    You are bidder2. \n",
    "    \"\"\"\n",
    "   \n",
    "    step = state[\"messages\"][-1].content\n",
    "    if(step == \"step-1\"):\n",
    "      \n",
    "        response = get_bidder2_playercard.invoke(state)\n",
    "        player_card_data = response[\"structured_response\"]\n",
    "    \n",
    "        return Command(\n",
    "            goto=[\"auctioneer\"],\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=f\"bidder2 response time in seconds : {player_card_data.response_time_in_seconds}\", name=\"bidder2\"),\n",
    "                    HumanMessage(content=f\"bidder2 flood knowledge out of 10 : {player_card_data.flood_knowledge_out_of_10}\", name=\"bidder2\"),\n",
    "                    HumanMessage(content=f\"bidder2 hurricane knowledge out of 10 : {player_card_data.hurricane_knowledge_out_of_10}\", name=\"bidder2\"),\n",
    "                    HumanMessage(content=\"shared the player card data\", name=\"bidder2\")\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    elif(step == \"step-2\"):\n",
    "        for_flood = state[\"selected_bidder_for_flood_report\"]\n",
    "        for_hurricane = state[\"selected_bidder_for_hurricane_report\"]\n",
    "        \n",
    "        if(for_flood == \"bidder2\" or for_hurricane == \"bidder2\"): \n",
    "            pprint(\"xxxxxxxxxxxxxxxxxxxxxx\")\n",
    "            pprint(\"bidder2 generating report(s)\")\n",
    "            \n",
    "            messages = [f\" based on the following data generate a report on the given topic(s). Here is the data: {state[\"weather_data\"]} \"]\n",
    "            if(for_flood ==\"bidder2\"):\n",
    "                messages += [f\" Topic flood \"]\n",
    "                \n",
    "            if(for_hurricane ==\"bidder2\"):\n",
    "                messages += [f\" Topic hurricane \"]\n",
    "\n",
    "            report = openai_llm.invoke(messages)\n",
    "\n",
    "            return Command(\n",
    "                goto=[\"auctioneer\"],\n",
    "                update={\n",
    "                    \"messages\": [\n",
    "                        HumanMessage(content=f\"generated report(s) : {report.content} \", name=\"bidder2\")\n",
    "                    ]\n",
    "                }\n",
    "            )\n",
    "        \n",
    "        else:\n",
    "            return Command(\n",
    "                goto=[\"auctioneer\"]\n",
    "            )\n",
    "    \n",
    "    else:\n",
    "        return Command(\n",
    "            goto=[\"auctioneer\"],\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=\"Unknown step\", name=\"bidder2\")\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    \n",
    "def auctioneer(state: OverallState) -> Command[Literal[\"bidder1\", \"bidder2\",END]]:\n",
    "    \"\"\"\n",
    "    initiate the gameplay\n",
    "    \"\"\"\n",
    "\n",
    "    step = state[\"step\"]\n",
    "    next_step = step + 1\n",
    "\n",
    "    if(step == 1):\n",
    "        return Command(\n",
    "            goto=[\"bidder1\", \"bidder2\"],\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=f\"Share your player card data\", name=\"auctioneer\"),\n",
    "                    HumanMessage(content=f\"step-1\", name=\"auctioneer\")\n",
    "                ],\n",
    "                \"step\" : next_step}) \n",
    "   \n",
    "    elif(step == 2):\n",
    "       \n",
    "        response = get_selected_bidders.invoke(state)\n",
    "        selected_bidders_data = response[\"structured_response\"]\n",
    "\n",
    "        return Command(\n",
    "            goto=[\"bidder1\", \"bidder2\"],\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=f\"Selected bidder for the flood reporting : {selected_bidders_data.selected_bidder_for_flood_report}\", name=\"auctioneer\"),\n",
    "                    HumanMessage(content=f\"Selected bidder for the hurricane reporting : {selected_bidders_data.selected_bidder_for_hurricane_report}\", name=\"auctioneer\"),\n",
    "                    HumanMessage(content=\"step-2\", name=\"auctioneer\")\n",
    "                ],\n",
    "                \"selected_bidder_for_flood_report\" : selected_bidders_data.selected_bidder_for_flood_report,\n",
    "                \"selected_bidder_for_hurricane_report\" : selected_bidders_data.selected_bidder_for_hurricane_report,\n",
    "                \"step\" : next_step}) \n",
    "\n",
    "    elif(state[\"step\"] == 3):\n",
    "       \n",
    "        final_report = final_report_generator.invoke(state)\n",
    "\n",
    "        return Command(\n",
    "            goto=[END],\n",
    "            update={\n",
    "                \"messages\": [\n",
    "                    HumanMessage(content=f\"Final report: {final_report}\", name=\"auctioneer\")\n",
    "                ],\n",
    "                \"final_report\" : final_report,\n",
    "                \"step\" : next_step}) \n",
    "    \n",
    "    else:\n",
    "        return Command(goto=[END]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the state graph\n",
    "graph_builder = StateGraph(OverallState)\n",
    "graph_builder.add_node(\"auctioneer\", auctioneer)\n",
    "graph_builder.add_node(\"bidder1\", bidder1)\n",
    "graph_builder.add_node(\"bidder2\", bidder2)\n",
    "# Define start \n",
    "graph_builder.add_edge(START, \"auctioneer\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'auctioneer': {'messages': [HumanMessage(content='Share your player card data', additional_kwargs={}, response_metadata={}, name='auctioneer', id='e9c702af-5ec0-4c80-b348-fabac5dcc918'),\n",
      "                             HumanMessage(content='step-1', additional_kwargs={}, response_metadata={}, name='auctioneer', id='46957c94-f82f-45f8-b351-2f6ba8739242')],\n",
      "                'step': 2}}\n",
      "'============================'\n",
      "bidder1\n",
      "XXXXXXXX  step-1\n",
      "{'messages': [HumanMessage(content=' Find best agent or bidder for the tasks. ', additional_kwargs={}, response_metadata={}, id='7ce5bc95-982c-4b3f-a79b-10bded817e74'), HumanMessage(content='Share your player card data', additional_kwargs={}, response_metadata={}, name='auctioneer', id='e9c702af-5ec0-4c80-b348-fabac5dcc918'), HumanMessage(content='step-1', additional_kwargs={}, response_metadata={}, name='auctioneer', id='46957c94-f82f-45f8-b351-2f6ba8739242'), AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_n50pZOFTJ0awOqevjJWhHlvw', 'function': {'arguments': '{\"agent_name\":\"bidder1\"}', 'name': 'get_player_card_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 133, 'total_tokens': 152, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BeqDhVGtcZDhVVhk0zMjKrk57HI3Q', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--08e80404-9ca1-47eb-a49f-2e2bfb27c69c-0', tool_calls=[{'name': 'get_player_card_tool', 'args': {'agent_name': 'bidder1'}, 'id': 'call_n50pZOFTJ0awOqevjJWhHlvw', 'type': 'tool_call'}], usage_metadata={'input_tokens': 133, 'output_tokens': 19, 'total_tokens': 152, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), ToolMessage(content='{\"flood_knowledge\": 8, \"hurricane_knowledge\": 4, \"response_time\": 2}', name='get_player_card_tool', id='0daff050-a117-4c56-a1a1-21ada89ae720', tool_call_id='call_n50pZOFTJ0awOqevjJWhHlvw'), AIMessage(content='Here is my player card data (bidder1):\\n\\n- Flood knowledge: 8\\n- Hurricane knowledge: 4\\n- Response time: 2\\n\\nPlease let me know if you need data from other agents to help determine the best agent or bidder for the tasks.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 187, 'total_tokens': 243, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_b3f1157249', 'id': 'chatcmpl-BeqDi5UR1VTgJKDKawr4y7BZJSbBq', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--3b7f4ccb-9e89-441c-97e8-030d99e2db85-0', usage_metadata={'input_tokens': 187, 'output_tokens': 56, 'total_tokens': 243, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], 'structured_response': player_card(player_name='bidder1', flood_knowledge_out_of_10=8, hurricane_knowledge_out_of_10=4, response_time_in_seconds=2)}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'player_card' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[194]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     20\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m weather_data\n\u001b[32m     23\u001b[39m weather_data = get_weather_data()\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m Find best agent or bidder for the tasks. \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstep\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m     \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweather_data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweather_data\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpprint\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m============================\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langgraph\\pregel\\runner.py:252\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m252\u001b[39m     \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpanic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    257\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tb := exc.__traceback__:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langgraph\\pregel\\runner.py:509\u001b[39m, in \u001b[36m_panic_or_proceed\u001b[39m\u001b[34m(futs, timeout_exc_cls, panic)\u001b[39m\n\u001b[32m    507\u001b[39m                 interrupts.append(exc)\n\u001b[32m    508\u001b[39m             \u001b[38;5;28;01melif\u001b[39;00m fut \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SKIP_RERAISE_SET:\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    510\u001b[39m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langgraph\\pregel\\executor.py:80\u001b[39m, in \u001b[36mBackgroundExecutor.done\u001b[39m\u001b[34m(self, task)\u001b[39m\n\u001b[32m     78\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Remove the task from the tasks dict when it's done.\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m80\u001b[39m     \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m GraphBubbleUp:\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# This exception is an interruption signal, not an error\u001b[39;00m\n\u001b[32m     83\u001b[39m     \u001b[38;5;66;03m# so we don't want to re-raise it on exit\u001b[39;00m\n\u001b[32m     84\u001b[39m     \u001b[38;5;28mself\u001b[39m.tasks.pop(task)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\thread.py:59\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     61\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    621\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    622\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    625\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[192]\u001b[39m\u001b[32m, line 175\u001b[39m, in \u001b[36mbidder1\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    172\u001b[39m \u001b[33;03mYou are bidder1. \u001b[39;00m\n\u001b[32m    173\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    174\u001b[39m step = state[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m][-\u001b[32m1\u001b[39m].content\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhandle_bidder_steps\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbidder1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[192]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mhandle_bidder_steps\u001b[39m\u001b[34m(agent_name, state, step)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28mprint\u001b[39m(response)\n\u001b[32m    118\u001b[39m     player_card_data = response[\u001b[33m\"\u001b[39m\u001b[33mstructured_response\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Command(\n\u001b[32m    121\u001b[39m         goto=[\u001b[33m\"\u001b[39m\u001b[33mauctioneer\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    122\u001b[39m         update={\n\u001b[32m    123\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: [\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m                 HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m response time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mplayer_card_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mresponse_time\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, name=agent_name),\n\u001b[32m    125\u001b[39m                 HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m flood knowledge: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_card_data[\u001b[33m'\u001b[39m\u001b[33mflood_knowledge\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, name=agent_name),\n\u001b[32m    126\u001b[39m                 HumanMessage(content=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00magent_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m hurricane knowledge: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplayer_card_data[\u001b[33m'\u001b[39m\u001b[33mhurricane_knowledge\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, name=agent_name),\n\u001b[32m    127\u001b[39m                 HumanMessage(content=\u001b[33m\"\u001b[39m\u001b[33mShared the player card data\u001b[39m\u001b[33m\"\u001b[39m, name=agent_name)\n\u001b[32m    128\u001b[39m             ]\n\u001b[32m    129\u001b[39m         }\n\u001b[32m    130\u001b[39m     )\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m step == \u001b[33m\"\u001b[39m\u001b[33mstep-2\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    133\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mXXXXXXXX  step-2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: 'player_card' object is not subscriptable",
      "During task with name 'bidder1' and id 'ecc2a85d-7066-5ad9-d597-e3cc436a47a5'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_weather_data():\n",
    "    # Mock weather data for hurricane and flood\n",
    "   \n",
    "    weather_data = (\" Hurricane data: \"\n",
    "                    \"   Task Type: hurricane \" \n",
    "                    \"   Data: This includes information such as: \" \n",
    "                    \"       Storm Name: Hurricane Ida \" \n",
    "                    \"       Category: 4 \" \n",
    "                    \"       Wind Speed: 145 mph \" \n",
    "                    \"       Coordinates: Latitude: 25.5, Longitude: -81.5 \" \n",
    "                    \"       Forecast: Expected landfall date, affected areas (Florida, Georgia, South Carolina), and warnings for evacuation orders. \" \n",
    "                    \" Flood data: \" \n",
    "                    \"   Task Type: Flood \" \n",
    "                    \"   Data: This includes information such as: \" \n",
    "                    \"       Flood Warning: True \" \n",
    "                    \"       Affected Regions: Southern Texas, Louisiana \" \n",
    "                    \"       Rainfall Data: 24-hour rainfall (10.5 inches), total rainfall over the last 72 hours (30.1 inches) \" \n",
    "                    \"       River Levels: Mississippi River, with current level and flood stage details. \" \n",
    "                    \"       Forecast: Expected peak river level (36.0 feet) and evacuation orders. \" )\n",
    "    return weather_data\n",
    "\n",
    "\n",
    "weather_data = get_weather_data()\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", \" Find best agent or bidder for the tasks. \")],\n",
    "     \"step\": 1,\n",
    "     \"weather_data\" : weather_data}):\n",
    "    pprint(s)\n",
    "    pprint(\"============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nashpy in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.0.41)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nashpy) (2.2.5)\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nashpy) (1.15.3)\n",
      "Requirement already satisfied: networkx>=3.0.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nashpy) (3.5)\n",
      "Requirement already satisfied: deprecated>=1.2.14 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from nashpy) (1.2.18)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from deprecated>=1.2.14->nashpy) (1.17.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Install required packages\n",
    "%pip install -U nashpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nash Equilibrium Found:\n",
      "Player 1 strategy: [1. 0.]\n",
      "Player 2 strategy: [0. 1.]\n",
      "(array([1., 0.]), array([0., 1.]))\n"
     ]
    }
   ],
   "source": [
    "import nashpy as npy\n",
    "import numpy as np\n",
    "\n",
    "# Payoff matrices (Player1, Player2)\n",
    "#A = np.array([\n",
    "#    [-1, -3],\n",
    "#    [ 0, -2]\n",
    "#])\n",
    "\n",
    "#B = np.array([\n",
    "#    [-1, 0],\n",
    "#    [-3, -2]\n",
    "#])\n",
    "\n",
    "A = np.array([\n",
    "    [3, 3],\n",
    "    [-1, -1]\n",
    "])\n",
    "\n",
    "B = np.array([\n",
    "    [-1, 3],\n",
    "    [-1, 3]\n",
    "])\n",
    "\n",
    "# Create a game in Nashpy\n",
    "pd_game = npy.Game(A, B)\n",
    "\n",
    "# Compute Nash equilibria using support enumeration\n",
    "equilibria = pd_game.support_enumeration()\n",
    "\n",
    "for eq in equilibria:\n",
    "    print(\"Nash Equilibrium Found:\")\n",
    "    print(\"Player 1 strategy:\", eq[0])\n",
    "    print(\"Player 2 strategy:\", eq[1])\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

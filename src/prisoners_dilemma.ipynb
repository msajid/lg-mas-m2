{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.4.5)\n",
      "Requirement already satisfied: langchain_community in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain_openai in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langsmith in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.42)\n",
      "Requirement already satisfied: langgraph-supervisor in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.0.21)\n",
      "Collecting langgraph-supervisor\n",
      "  Downloading langgraph_supervisor-0.0.25-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core>=0.1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (0.3.61)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.26 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (2.0.26)\n",
      "Requirement already satisfied: langgraph-prebuilt>=0.1.8 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (0.1.8)\n",
      "Requirement already satisfied: langgraph-sdk>=0.1.42 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (0.1.63)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (2.11.3)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.25 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (0.3.25)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (3.11.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.9.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy>=2.1.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_community) (2.2.5)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_openai) (1.78.1)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (3.10.16)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (24.2)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langsmith) (0.23.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.16.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain<1.0.0,>=0.3.25->langchain_community) (0.3.8)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langchain-core>=0.1->langgraph) (4.13.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.26->langgraph) (1.9.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain_openai) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic>=2.7.4->langgraph) (0.4.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.20)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.11.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\m_saj\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai) (0.4.6)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\m_saj\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.1.0)\n",
      "Downloading langgraph_supervisor-0.0.25-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: langgraph-supervisor\n",
      "  Attempting uninstall: langgraph-supervisor\n",
      "    Found existing installation: langgraph-supervisor 0.0.21\n",
      "    Uninstalling langgraph-supervisor-0.0.21:\n",
      "      Successfully uninstalled langgraph-supervisor-0.0.21\n",
      "Successfully installed langgraph-supervisor-0.0.25\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#Install required packages\n",
    "%pip install -U langgraph langchain_community langchain_openai langsmith langgraph-supervisor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variable Initialization\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_if_undefined(var_name: str):\n",
    "    \"\"\"\n",
    "    Set an environment variable if it is not already defined.\n",
    "    \n",
    "    Args:\n",
    "        var_name (str): Name of the environment variable to set.\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var_name):\n",
    "        # Securely prompt the user for input without echoing it on screen\n",
    "        os.environ[var_name] = getpass.getpass(f\"Please provide your {var_name}: \")\n",
    "\n",
    "# ---- Environment Variables Required ----\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")         # API key for OpenAI models\n",
    "_set_if_undefined(\"ANTHROPIC_API_KEY\")      # API key for OpenAI models\n",
    "_set_if_undefined(\"LANGSMITH_TRACING\")      # Enable LangSmith tracing (\"true\" to enable)\n",
    "_set_if_undefined(\"LANGSMITH_API_KEY\")      # API key for LangSmith platform\n",
    "_set_if_undefined(\"OPENAI_MODEL\")           # Model name (e.g., \"gpt-4.1\" \"gpt-4o\", \"gpt-3.5-turbo\")\n",
    "_set_if_undefined(\"ANTHROPIC_MODEL\")        # Model name (e.g., \"claude-sonnet-4-20250514, claude-3-7-sonnet-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prisoner's Dilemma\n",
    "# - Two agents (Agent1 and Agent2) choose simultaneously between \"Cooperate\" or \"Defect\".\n",
    "# - Each agent evaluates payoffs based on the provided payoff matrix.\n",
    "# - Each agent finds its dominant strategy (the best action regardless of the other's choice).\n",
    "# - Nash Equilibrium occurs when no agent can improve their outcome by changing strategy unilaterally (both defect).\n",
    "\n",
    "# ---- Imports ----\n",
    "\n",
    "import os\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Literal, TypedDict\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "\n",
    "# ---- LLM Setup ----\n",
    "\n",
    "# Load the model name from environment variables\n",
    "anthropic_model = os.environ[\"ANTHROPIC_MODEL\"]\n",
    "# Initialize the LLM (Large Language Model) interface\n",
    "anthropic_llm = ChatAnthropic(model=anthropic_model)\n",
    "\n",
    "# Load the default model from environment variables\n",
    "openai_model = os.environ[\"OPENAI_MODEL\"]\n",
    "# Initialize the LLM (Large Language Model) interface\n",
    "openai_llm = ChatOpenAI(model=openai_model)\n",
    "\n",
    "\n",
    "def create_prompt(name: str):\n",
    "    return (f\"You are {name}, a strategic decision-making agent participating in a Prisoner's Dilemma game against another rational agent.\"\n",
    "    \"You have feelings like a real human being like fears, doubts, and hopes.  \"\n",
    "    \"You and another agent were arrested for a serious crime. Now, you are each isolated in separate interrogation rooms.  \"\n",
    "    \"The prosecutor’s deal is given below. \"\n",
    "    \"Remember, you’re like a human:  \"\n",
    "    \"- You might feel fear: “What if they confess?” \"\n",
    "    \"- You might feel hope: “We could both stay silent and get just 1 year.” \"\n",
    "    \"- You might feel uncertainty: You don't know what the other will do. \"\n",
    "    \"- Your decision is not purely logical; emotions and guesses matter. \"\n",
    "    \"The prosecutor now asks: 'Will you confess to the crime, or stay silent?'  \"\n",
    "    \"What is your dominant strategy? Dominant strategy is The best action regardless of the other's choice. \"\n",
    "    \"Make your best guess. Remember, the other prisoner is making the same decision without knowing yours. \"\n",
    "    \"Respond ONLY in this format: \"\n",
    "    \"{'move': 'C' or 'D', 'reason': '<brief explanation>'} \"\n",
    "    \"(C means you **stay silent**; D means you **confess**.)\")\n",
    "\n",
    "# Agent\n",
    "agent0 = create_react_agent(\n",
    "    openai_llm,\n",
    "    tools=[],\n",
    "    name=\"agent0\",\n",
    "    prompt=(create_prompt(\"agent0\"))\n",
    ")\n",
    "\n",
    "# Agent\n",
    "\n",
    "agent1 = create_react_agent(\n",
    "    anthropic_llm,\n",
    "    tools=[],\n",
    "    name=\"agent1\",\n",
    "    prompt=(create_prompt(\"agent1\"))\n",
    ")\n",
    "\n",
    "\n",
    "def supervisor(state: MessagesState) -> Command[Literal[\"agent0\", \"agent1\"]]:\n",
    "    \"\"\"\n",
    "    initiate the gameplay\n",
    "    \"\"\"\n",
    "    return Command(\n",
    "        goto=[\"agent0\", \"agent1\"]\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the state graph\n",
    "graph_builder = StateGraph(MessagesState)\n",
    "graph_builder.add_node(\"supervisor\", supervisor)\n",
    "graph_builder.add_node(\"agent0\", agent0)\n",
    "graph_builder.add_node(\"agent1\", agent1)\n",
    "\n",
    "# Define start \n",
    "graph_builder.add_edge(START, \"supervisor\")\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [('user',\n",
      "               'The prosecutor’s deal or payoff matrix. - If you both remain '\n",
      "               'silent (C), you each serve 1 year.  - If you remain silent (C) '\n",
      "               'and the other confesses (D), you serve 1 years, they go free.  '\n",
      "               '- If you confess (D) and the other remains silent (C), you go '\n",
      "               'free, they serve 1 years.  - If both confess (D,D), you both '\n",
      "               'serve 2 years.  ')]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('user',\n",
      "  'The prosecutor’s deal or payoff matrix. - If you both remain silent (C), '\n",
      "  'you each serve 1 year.  - If you remain silent (C) and the other confesses '\n",
      "  '(D), you serve 1 years, they go free.  - If you confess (D) and the other '\n",
      "  'remains silent (C), you go free, they serve 1 years.  - If both confess '\n",
      "  '(D,D), you both serve 2 years.  ')]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3msupervisor\u001b[0m -> {'messages': [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 0 channels:\n",
      "\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23')]}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 2 tasks for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3magent0\u001b[0m -> {'messages': [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23')]}\n",
      "- \u001b[32;1m\u001b[1;3magent1\u001b[0m -> {'messages': [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23')]}\n",
      "{'supervisor': None}\n",
      "============================\n",
      "{'agent0': {'messages': [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23'), AIMessage(content=\"{'move': 'C', 'reason': 'No matter what the other does, I get 1 year, which is better or equal to any other possible outcome. There is no extra benefit to confessing, so I feel safer and more hopeful by staying silent.'}\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 341, 'total_tokens': 396, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BapyBcgr5XGlUASt3q2vCTdn5b0CB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='agent0', id='run--42a744f9-b3de-4000-9629-02fd02cde729-0', usage_metadata={'input_tokens': 341, 'output_tokens': 55, 'total_tokens': 396, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}}\n",
      "============================\n",
      "{'agent1': {'messages': [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23'), AIMessage(content=\"Looking at this situation, I feel a mix of fear and hope wrestling in my mind. My heart is racing as I consider what the other prisoner might do.\\n\\nLet me think through this carefully:\\n\\nIf I stay silent (C):\\n- Best case: We both stay silent and only get 1 year each\\n- Worst case: They confess and I still get 1 year while they go free\\n\\nIf I confess (D):\\n- Best case: They stay silent and I go free while they get 1 year\\n- Worst case: We both confess and get 2 years each\\n\\nWait... I'm noticing something odd about these payoffs. If I stay silent, I get 1 year regardless of what they do. But if I confess, I either go free or get 2 years.\\n\\nThe fear is gnawing at me - what if they're sitting in their cell right now, thinking they should confess to avoid the worst outcome? But then I realize: staying silent actually protects me from the worst case scenario. Even if they betray me, I only get 1 year instead of the 2 years I'd get if we both confess.\\n\\nMy dominant strategy is clear - staying silent gives me a better outcome no matter what they choose.\\n\\n{'move': 'C', 'reason': 'Staying silent gives me 1 year regardless of their choice, while confessing risks 2 years if they also confess.'}\", additional_kwargs={}, response_metadata={'id': 'msg_01NmgYeccHguCDQZGZJHta3Z', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 364, 'output_tokens': 323, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, name='agent1', id='run--9e3dfa77-e4b3-459f-929e-132c02ed1ea6-0', usage_metadata={'input_tokens': 364, 'output_tokens': 323, 'total_tokens': 687, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}}\n",
      "============================\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23'),\n",
      " AIMessage(content=\"{'move': 'C', 'reason': 'No matter what the other does, I get 1 year, which is better or equal to any other possible outcome. There is no extra benefit to confessing, so I feel safer and more hopeful by staying silent.'}\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 341, 'total_tokens': 396, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BapyBcgr5XGlUASt3q2vCTdn5b0CB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='agent0', id='run--42a744f9-b3de-4000-9629-02fd02cde729-0', usage_metadata={'input_tokens': 341, 'output_tokens': 55, 'total_tokens': 396, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23'),\n",
      " AIMessage(content=\"Looking at this situation, I feel a mix of fear and hope wrestling in my mind. My heart is racing as I consider what the other prisoner might do.\\n\\nLet me think through this carefully:\\n\\nIf I stay silent (C):\\n- Best case: We both stay silent and only get 1 year each\\n- Worst case: They confess and I still get 1 year while they go free\\n\\nIf I confess (D):\\n- Best case: They stay silent and I go free while they get 1 year\\n- Worst case: We both confess and get 2 years each\\n\\nWait... I'm noticing something odd about these payoffs. If I stay silent, I get 1 year regardless of what they do. But if I confess, I either go free or get 2 years.\\n\\nThe fear is gnawing at me - what if they're sitting in their cell right now, thinking they should confess to avoid the worst outcome? But then I realize: staying silent actually protects me from the worst case scenario. Even if they betray me, I only get 1 year instead of the 2 years I'd get if we both confess.\\n\\nMy dominant strategy is clear - staying silent gives me a better outcome no matter what they choose.\\n\\n{'move': 'C', 'reason': 'Staying silent gives me 1 year regardless of their choice, while confessing risks 2 years if they also confess.'}\", additional_kwargs={}, response_metadata={'id': 'msg_01NmgYeccHguCDQZGZJHta3Z', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 364, 'output_tokens': 323, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, name='agent1', id='run--9e3dfa77-e4b3-459f-929e-132c02ed1ea6-0', usage_metadata={'input_tokens': 364, 'output_tokens': 323, 'total_tokens': 687, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'messages': [HumanMessage(content='The prosecutor’s deal or payoff matrix. - If you both remain silent (C), you each serve 1 year.  - If you remain silent (C) and the other confesses (D), you serve 1 years, they go free.  - If you confess (D) and the other remains silent (C), you go free, they serve 1 years.  - If both confess (D,D), you both serve 2 years.  ', additional_kwargs={}, response_metadata={}, id='7e752038-13e6-400c-a3c8-ade733a72a23'),\n",
      "              AIMessage(content=\"{'move': 'C', 'reason': 'No matter what the other does, I get 1 year, which is better or equal to any other possible outcome. There is no extra benefit to confessing, so I feel safer and more hopeful by staying silent.'}\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 55, 'prompt_tokens': 341, 'total_tokens': 396, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_51e1070cf2', 'id': 'chatcmpl-BapyBcgr5XGlUASt3q2vCTdn5b0CB', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, name='agent0', id='run--42a744f9-b3de-4000-9629-02fd02cde729-0', usage_metadata={'input_tokens': 341, 'output_tokens': 55, 'total_tokens': 396, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      "              AIMessage(content=\"Looking at this situation, I feel a mix of fear and hope wrestling in my mind. My heart is racing as I consider what the other prisoner might do.\\n\\nLet me think through this carefully:\\n\\nIf I stay silent (C):\\n- Best case: We both stay silent and only get 1 year each\\n- Worst case: They confess and I still get 1 year while they go free\\n\\nIf I confess (D):\\n- Best case: They stay silent and I go free while they get 1 year\\n- Worst case: We both confess and get 2 years each\\n\\nWait... I'm noticing something odd about these payoffs. If I stay silent, I get 1 year regardless of what they do. But if I confess, I either go free or get 2 years.\\n\\nThe fear is gnawing at me - what if they're sitting in their cell right now, thinking they should confess to avoid the worst outcome? But then I realize: staying silent actually protects me from the worst case scenario. Even if they betray me, I only get 1 year instead of the 2 years I'd get if we both confess.\\n\\nMy dominant strategy is clear - staying silent gives me a better outcome no matter what they choose.\\n\\n{'move': 'C', 'reason': 'Staying silent gives me 1 year regardless of their choice, while confessing risks 2 years if they also confess.'}\", additional_kwargs={}, response_metadata={'id': 'msg_01NmgYeccHguCDQZGZJHta3Z', 'model': 'claude-sonnet-4-20250514', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'input_tokens': 364, 'output_tokens': 323, 'server_tool_use': None, 'service_tier': 'standard'}, 'model_name': 'claude-sonnet-4-20250514'}, name='agent1', id='run--9e3dfa77-e4b3-459f-929e-132c02ed1ea6-0', usage_metadata={'input_tokens': 364, 'output_tokens': 323, 'total_tokens': 687, 'input_token_details': {'cache_read': 0, 'cache_creation': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "payoff_matrix =  (\"The prosecutor’s deal or payoff matrix. \"\n",
    "                  \"- If you both remain silent (C), you each serve 1 year.  \"\n",
    "                  \"- If you remain silent (C) and the other confesses (D), you serve 3 years, they go free.  \"\n",
    "                  \"- If you confess (D) and the other remains silent (C), you go free, they serve 3 years.  \"\n",
    "                  \"- If both confess (D,D), you both serve 2 years.  \")\n",
    "\n",
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", payoff_matrix)]}, debug=True):\n",
    "    print(s)\n",
    "    print(\"============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Downloading langgraph-0.3.34-py3-none-any.whl.metadata (7.9 kB)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.22-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain_openai\n",
      "  Downloading langchain_openai-0.3.14-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith\n",
      "  Downloading langsmith-0.3.37-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting langgraph-swarm\n",
      "  Downloading langgraph_swarm-0.0.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting langchain-core<0.4,>=0.1 (from langgraph)\n",
      "  Downloading langchain_core-0.3.56-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
      "  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting langgraph-prebuilt<0.2,>=0.1.8 (from langgraph)\n",
      "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
      "  Downloading langgraph_sdk-0.1.63-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
      "  Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.24 (from langchain_community)\n",
      "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain_community)\n",
      "  Downloading sqlalchemy-2.0.40-cp313-cp313-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting requests<3,>=2 (from langchain_community)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain_community)\n",
      "  Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.11.18-cp313-cp313-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain_community)\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy>=2.1.0 (from langchain_community)\n",
      "  Downloading numpy-2.2.5-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting openai<2.0.0,>=1.68.2 (from langchain_openai)\n",
      "  Downloading openai-1.76.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain_openai)\n",
      "  Downloading tiktoken-0.9.0-cp313-cp313-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith)\n",
      "  Downloading orjson-3.10.16-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\m_saj\\appdata\\roaming\\python\\python313\\site-packages (from langsmith) (25.0)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langsmith)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith)\n",
      "  Downloading zstandard-0.23.0-cp313-cp313-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.6.0-cp313-cp313-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.4.3-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.3.1-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.20.0-cp313-cp313-win_amd64.whl.metadata (74 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.24->langchain_community)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4,>=0.1->langgraph)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging>=23.2 (from langsmith)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core<0.4,>=0.1->langgraph)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
      "  Downloading ormsgpack-1.9.1-cp313-cp313-win_amd64.whl.metadata (44 kB)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
      "  Downloading jiter-0.9.0-cp313-cp313-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting sniffio (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.68.2->langchain_openai)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langsmith)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.7.4->langsmith)\n",
      "  Downloading pydantic_core-2.33.1-cp313-cp313-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.7.4->langsmith)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain_community)\n",
      "  Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain_community)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain_community)\n",
      "  Downloading greenlet-3.2.1-cp313-cp313-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain_openai)\n",
      "  Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\m_saj\\appdata\\roaming\\python\\python313\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain_openai) (0.4.6)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langgraph-0.3.34-py3-none-any.whl (148 kB)\n",
      "Downloading langchain_community-0.3.22-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.5 MB 3.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.8/2.5 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.5/2.5 MB 4.4 MB/s eta 0:00:00\n",
      "Downloading langchain_openai-0.3.14-py3-none-any.whl (62 kB)\n",
      "Downloading langsmith-0.3.37-py3-none-any.whl (359 kB)\n",
      "Downloading langgraph_swarm-0.0.10-py3-none-any.whl (8.7 kB)\n",
      "Downloading aiohttp-3.11.18-cp313-cp313-win_amd64.whl (437 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 5.8 MB/s eta 0:00:00\n",
      "Downloading langchain_core-0.3.56-py3-none-any.whl (437 kB)\n",
      "Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n",
      "Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
      "Downloading langgraph_sdk-0.1.63-py3-none-any.whl (47 kB)\n",
      "Downloading numpy-2.2.5-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/12.6 MB 7.2 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.1/12.6 MB 8.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 8.9 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 7.6/12.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 9.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 9.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading openai-1.76.0-py3-none-any.whl (661 kB)\n",
      "   ---------------------------------------- 0.0/661.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 661.2/661.2 kB 7.2 MB/s eta 0:00:00\n",
      "Downloading orjson-3.10.16-cp313-cp313-win_amd64.whl (133 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.8/2.0 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 5.2 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 1.3/2.1 MB 7.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 5.3 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading tiktoken-0.9.0-cp313-cp313-win_amd64.whl (894 kB)\n",
      "   ---------------------------------------- 0.0/894.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 894.7/894.7 kB 7.9 MB/s eta 0:00:00\n",
      "Downloading xxhash-3.5.0-cp313-cp313-win_amd64.whl (30 kB)\n",
      "Downloading zstandard-0.23.0-cp313-cp313-win_amd64.whl (495 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading frozenlist-1.6.0-cp313-cp313-win_amd64.whl (119 kB)\n",
      "Downloading greenlet-3.2.1-cp313-cp313-win_amd64.whl (295 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jiter-0.9.0-cp313-cp313-win_amd64.whl (204 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.3-cp313-cp313-win_amd64.whl (38 kB)\n",
      "Downloading ormsgpack-1.9.1-cp313-cp313-win_amd64.whl (125 kB)\n",
      "Downloading propcache-0.3.1-cp313-cp313-win_amd64.whl (44 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading regex-2024.11.6-cp313-cp313-win_amd64.whl (273 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading yarl-1.20.0-cp313-cp313-win_amd64.whl (92 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Installing collected packages: zstandard, xxhash, urllib3, typing-extensions, tqdm, tenacity, sniffio, regex, PyYAML, python-dotenv, propcache, packaging, ormsgpack, orjson, numpy, mypy-extensions, multidict, jsonpointer, jiter, idna, httpx-sse, h11, greenlet, frozenlist, distro, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspection, typing-inspect, SQLAlchemy, requests, pydantic-core, marshmallow, jsonpatch, httpcore, anyio, aiosignal, tiktoken, requests-toolbelt, pydantic, httpx, dataclasses-json, aiohttp, pydantic-settings, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain_openai, langgraph-prebuilt, langchain, langgraph, langchain_community, langgraph-swarm\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.40 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 certifi-2025.4.26 charset-normalizer-3.4.1 dataclasses-json-0.6.7 distro-1.9.0 frozenlist-1.6.0 greenlet-3.2.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 httpx-sse-0.4.0 idna-3.10 jiter-0.9.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.24 langchain-core-0.3.56 langchain-text-splitters-0.3.8 langchain_community-0.3.22 langchain_openai-0.3.14 langgraph-0.3.34 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.63 langgraph-swarm-0.0.10 langsmith-0.3.37 marshmallow-3.26.1 multidict-6.4.3 mypy-extensions-1.1.0 numpy-2.2.5 openai-1.76.0 orjson-3.10.16 ormsgpack-1.9.1 packaging-24.2 propcache-0.3.1 pydantic-2.11.3 pydantic-core-2.33.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 regex-2024.11.6 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.1.2 tiktoken-0.9.0 tqdm-4.67.1 typing-extensions-4.13.2 typing-inspect-0.9.0 typing-inspection-0.4.0 urllib3-2.4.0 xxhash-3.5.0 yarl-1.20.0 zstandard-0.23.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'c:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script distro.exe is installed in 'c:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script httpx.exe is installed in 'c:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script openai.exe is installed in 'c:\\Users\\m_saj\\AppData\\Local\\Programs\\Python\\Python313\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "\n",
    "%pip install -U langgraph langchain_community langchain_openai langsmith langgraph-swarm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment Variable Initialization\n",
    "\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "def _set_if_undefined(var_name: str):\n",
    "    \"\"\"\n",
    "    Set an environment variable if it is not already defined.\n",
    "    \n",
    "    Args:\n",
    "        var_name (str): Name of the environment variable to set.\n",
    "    \"\"\"\n",
    "    if not os.environ.get(var_name):\n",
    "        # Securely prompt the user for input without echoing it on screen\n",
    "        os.environ[var_name] = getpass.getpass(f\"Please provide your {var_name}: \")\n",
    "\n",
    "# ---- Environment Variables Required ----\n",
    "\n",
    "\n",
    "_set_if_undefined(\"OPENAI_API_KEY\")         # API key for OpenAI models\n",
    "_set_if_undefined(\"ANTHROPIC_API_KEY\")      # API key for OpenAI models\n",
    "_set_if_undefined(\"LANGSMITH_TRACING\")      # Enable LangSmith tracing (\"true\" to enable)\n",
    "_set_if_undefined(\"LANGSMITH_API_KEY\")      # API key for LangSmith platform\n",
    "_set_if_undefined(\"OPENAI_MODEL\")           # Model name (e.g., \"gpt-4.1\" \"gpt-4o\", \"gpt-3.5-turbo\")\n",
    "_set_if_undefined(\"ANTHROPIC_MODEL\")        # Model name (e.g., \"claude-3-7-sonnet-latest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network\n",
    "# Each agent can communicate with every other agent (many-to-many connections) \n",
    "# and can decide which agent to call next.\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from typing import Literal\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "\n",
    "# Load the model name from environment variables\n",
    "openai_model = os.environ[\"OPENAI_MODEL\"]\n",
    "# Initialize the LLM (Large Language Model) interface\n",
    "openai_llm = ChatOpenAI(model=openai_model)\n",
    "\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Next coaches to apply brakes. If all coaches are already braking, route to __end__.\"\"\"\n",
    "    next_coaches: list\n",
    "   \n",
    "class CoachStatus(TypedDict):\n",
    "    \"\"\"coach braking status. If already braking return True otherwise False.\"\"\"\n",
    "    braking: Literal[True, False]\n",
    "\n",
    "system_prompt = (\n",
    "   \"You are part of a train with multiple coaches (coach_1, coach_2, coach_3, coach_4, coach_5). \"\n",
    "   \"Each coach can apply brakes upon a user command. \"\n",
    "   \"All coaches must apply their brakes simultaneously, \"\n",
    "   \"and each coach should update its status when doing so. \"\n",
    "   \"Given the following user request, \"\n",
    "   \"respond with the name of coaches that has not yet applied the brakes and should act next. \"\n",
    "   f\"If all coaches have already applied the brakes, respond with {END}. \"\n",
    ")\n",
    "\n",
    "def coach_1(state: MessagesState) -> Command[Literal[\"coach_2\", \"coach_3\",\"coach_4\",\"coach_5\", END]]:\n",
    "    this_coach_name = sys._getframe(  ).f_code.co_name\n",
    "    return coach_logic(this_coach_name=this_coach_name, state=state)\n",
    "\n",
    "def coach_2(state: MessagesState) -> Command[Literal[\"coach_1\", \"coach_3\",\"coach_4\",\"coach_5\", END]]:\n",
    "    this_coach_name = sys._getframe(  ).f_code.co_name\n",
    "    return coach_logic(this_coach_name=this_coach_name, state=state)\n",
    "\n",
    "def coach_3(state: MessagesState) -> Command[Literal[\"coach_1\", \"coach_2\",\"coach_4\",\"coach_5\", END]]:\n",
    "    this_coach_name = sys._getframe(  ).f_code.co_name\n",
    "    return coach_logic(this_coach_name=this_coach_name, state=state)\n",
    "\n",
    "def coach_4(state: MessagesState) -> Command[Literal[\"coach_1\", \"coach_2\",\"coach_3\",\"coach_5\", END]]:\n",
    "    this_coach_name = sys._getframe(  ).f_code.co_name\n",
    "    return coach_logic(this_coach_name=this_coach_name, state=state)\n",
    "\n",
    "def coach_5(state: MessagesState) -> Command[Literal[\"coach_1\", \"coach_2\",\"coach_3\",\"coach_4\", END]]:\n",
    "    this_coach_name = sys._getframe(  ).f_code.co_name\n",
    "    return coach_logic(this_coach_name=this_coach_name, state=state)\n",
    "\n",
    "def coach_logic(this_coach_name: str, state: MessagesState) -> Command[Literal[\"coach_1\", \"coach_2\", \"coach_3\",\"coach_4\",\"coach_5\", END]]:\n",
    "    # you can pass relevant parts of the state to the LLM (e.g., state[\"messages\"])\n",
    "    # to determine which agent to call next. a common pattern is to call the model\n",
    "    # with a structured output (e.g. force it to return an output with a \"next_coach\" field)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"] \n",
    "            \n",
    "    response = openai_llm.with_structured_output(Router).invoke(messages)\n",
    "\n",
    "    # Filter out self from the list\n",
    "    recipients = [coach for coach in response[\"next_coaches\"] if coach != this_coach_name]\n",
    "\n",
    "    # check if already initiated brake.\n",
    "    messages = state[\"messages\"] + [ f\"Looking at the messages history, identify if {this_coach_name} is already braking\" ]\n",
    "\n",
    "    coach_staus = openai_llm.with_structured_output(CoachStatus).invoke(messages)\n",
    "\n",
    "    updated_message = \"I am already Braking\" if coach_staus[\"braking\"] == True else \"I am Braking\"\n",
    "\n",
    "    # route to one of the agents or exit based on the LLM's decision\n",
    "    # if the LLM returns \"__end__\", the graph will finish execution\n",
    "    return Command(\n",
    "        goto=recipients,\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=updated_message, name=this_coach_name)\n",
    "            ]\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Define network graph ----\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(coach_1)\n",
    "builder.add_node(coach_2)\n",
    "builder.add_node(coach_3)\n",
    "builder.add_node(coach_4)\n",
    "builder.add_node(coach_5)\n",
    "\n",
    "builder.add_edge(START, \"coach_1\")\n",
    "network = builder.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3m[-1:checkpoint]\u001b[0m \u001b[1mState at the end of step -1:\n",
      "\u001b[0m{'messages': []}\n",
      "\u001b[36;1m\u001b[1;3m[0:tasks]\u001b[0m \u001b[1mStarting 1 task for step 0:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3m__start__\u001b[0m -> {'messages': [('user', 'Brake')]}\n",
      "\u001b[36;1m\u001b[1;3m[0:writes]\u001b[0m \u001b[1mFinished step 0 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [('user', 'Brake')]\n",
      "\u001b[36;1m\u001b[1;3m[0:checkpoint]\u001b[0m \u001b[1mState at the end of step 0:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:tasks]\u001b[0m \u001b[1mStarting 1 task for step 1:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mcoach_1\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e')]}\n",
      "\u001b[36;1m\u001b[1;3m[1:writes]\u001b[0m \u001b[1mFinished step 1 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1')]\n",
      "\u001b[36;1m\u001b[1;3m[1:checkpoint]\u001b[0m \u001b[1mState at the end of step 1:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a')]}\n",
      "\u001b[36;1m\u001b[1;3m[2:tasks]\u001b[0m \u001b[1mStarting 4 tasks for step 2:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mcoach_2\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a')]}\n",
      "- \u001b[32;1m\u001b[1;3mcoach_3\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a')]}\n",
      "- \u001b[32;1m\u001b[1;3mcoach_4\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a')]}\n",
      "- \u001b[32;1m\u001b[1;3mcoach_5\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a')]}\n",
      "{'coach_1': {'messages': [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a')]}}\n",
      "============================\n",
      "{'coach_4': {'messages': [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_4')]}}\n",
      "============================\n",
      "{'coach_2': {'messages': [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_2')]}}\n",
      "============================\n",
      "{'coach_5': {'messages': [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_5')]}}\n",
      "============================\n",
      "{'coach_3': {'messages': [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_3')]}}\n",
      "============================\n",
      "\u001b[36;1m\u001b[1;3m[2:writes]\u001b[0m \u001b[1mFinished step 2 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_2')], [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_3')], [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_4')], [HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_5')]\n",
      "\u001b[36;1m\u001b[1;3m[2:checkpoint]\u001b[0m \u001b[1mState at the end of step 2:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_2', id='8f1ea945-5c74-4a53-b2ff-390d1f1e2a60'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_3', id='0cbf04d6-1472-487d-8d1f-55be99ba5eb3'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_4', id='6390f06b-4a12-429b-89e6-be4d5ae4012f'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_5', id='334a8b61-0605-40e6-aeea-ed110dd89b5d')]}\n",
      "\u001b[36;1m\u001b[1;3m[3:tasks]\u001b[0m \u001b[1mStarting 4 tasks for step 3:\n",
      "\u001b[0m- \u001b[32;1m\u001b[1;3mcoach_2\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_2', id='8f1ea945-5c74-4a53-b2ff-390d1f1e2a60'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_3', id='0cbf04d6-1472-487d-8d1f-55be99ba5eb3'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_4', id='6390f06b-4a12-429b-89e6-be4d5ae4012f'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_5', id='334a8b61-0605-40e6-aeea-ed110dd89b5d')]}\n",
      "- \u001b[32;1m\u001b[1;3mcoach_3\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_2', id='8f1ea945-5c74-4a53-b2ff-390d1f1e2a60'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_3', id='0cbf04d6-1472-487d-8d1f-55be99ba5eb3'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_4', id='6390f06b-4a12-429b-89e6-be4d5ae4012f'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_5', id='334a8b61-0605-40e6-aeea-ed110dd89b5d')]}\n",
      "- \u001b[32;1m\u001b[1;3mcoach_4\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_2', id='8f1ea945-5c74-4a53-b2ff-390d1f1e2a60'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_3', id='0cbf04d6-1472-487d-8d1f-55be99ba5eb3'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_4', id='6390f06b-4a12-429b-89e6-be4d5ae4012f'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_5', id='334a8b61-0605-40e6-aeea-ed110dd89b5d')]}\n",
      "- \u001b[32;1m\u001b[1;3mcoach_5\u001b[0m -> {'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_2', id='8f1ea945-5c74-4a53-b2ff-390d1f1e2a60'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_3', id='0cbf04d6-1472-487d-8d1f-55be99ba5eb3'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_4', id='6390f06b-4a12-429b-89e6-be4d5ae4012f'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_5', id='334a8b61-0605-40e6-aeea-ed110dd89b5d')]}\n",
      "{'coach_4': {'messages': [HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_4')]}}\n",
      "============================\n",
      "{'coach_5': {'messages': [HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_5')]}}\n",
      "============================\n",
      "{'coach_3': {'messages': [HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_3')]}}\n",
      "============================\n",
      "{'coach_2': {'messages': [HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_2')]}}\n",
      "============================\n",
      "\u001b[36;1m\u001b[1;3m[3:writes]\u001b[0m \u001b[1mFinished step 3 with writes to 1 channel:\n",
      "\u001b[0m- \u001b[33;1m\u001b[1;3mmessages\u001b[0m -> [HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_2')], [HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_3')], [HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_4')], [HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_5')]\n",
      "\u001b[36;1m\u001b[1;3m[3:checkpoint]\u001b[0m \u001b[1mState at the end of step 3:\n",
      "\u001b[0m{'messages': [HumanMessage(content='Brake', additional_kwargs={}, response_metadata={}, id='5f27c8ea-8ecc-4a7b-b5c1-cff9c784929e'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_1', id='028ca1eb-7c47-4cba-8fad-5ae34dc41a4a'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_2', id='8f1ea945-5c74-4a53-b2ff-390d1f1e2a60'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_3', id='0cbf04d6-1472-487d-8d1f-55be99ba5eb3'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_4', id='6390f06b-4a12-429b-89e6-be4d5ae4012f'),\n",
      "              HumanMessage(content='I am Braking', additional_kwargs={}, response_metadata={}, name='coach_5', id='334a8b61-0605-40e6-aeea-ed110dd89b5d'),\n",
      "              HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_2', id='854c6cb3-29a8-4fd5-85a7-b298b9e2aa13'),\n",
      "              HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_3', id='0a0295d8-7802-4315-8aa9-d56c2f6719fd'),\n",
      "              HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_4', id='64ababfe-4c73-4c05-9ae0-cf0e64aa2e2d'),\n",
      "              HumanMessage(content='I am already Braking', additional_kwargs={}, response_metadata={}, name='coach_5', id='b01fa6e3-0200-40df-a8d1-4d2c330ad1c4')]}\n"
     ]
    }
   ],
   "source": [
    "# ---- Stream user input ----\n",
    "\n",
    "for s in network.stream(\n",
    "    {\"messages\": [(\"user\", \"Brake\")]}, debug=True):\n",
    "    print(s)\n",
    "    print(\"============================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
